\chapter{Related Work}\label{ch:related_work}
% intro to classic interpretation of articulated joints/parts with classical methods
From a computer vision perspective, the human body can be considered as a collection of rigid parts connected between them by a number of joints~\cite{Gong2016-kd}. Following %that line of reasoning
this approach, the goal of human pose estimation methods is to determine the two-dimensional or three-dimensional location of these joints and parts from an image or a sequence of images. Classical approaches usually address the modeling and estimation of these articulated poses building upon the seminal works of~\cite{Fischler1973-bi, Felzenszwalb2010-me} in pictorial structures and part-based models. Such is the case of Andriluka \etal~\cite{Andriluka2009-on}, who combines strong part detectors with pictorial structures, or Yang and Ramanan~\cite{Yang2011-vn} when proposing a mixture of non-oriented pictorial structures. Other works have further explored these methods~\cite{Sapp2010-dm, Pishchulin2013-zi, Kiefel2014-vm, Wang2013-wv}, even trying to address multi-person scenarios~\cite{Eichner2010-ey} and introducing spatio-temporal cues %for estimation 
in video sequences~\cite{Cherian2014-zf, Fathi2007-dc, Ferrari2008-ry, Zhang2015-js}.

% presentation of more holistic approaches with the first steps into DNN
More holistic approaches started to gain popularity with the inclusion of \gls{dl} techniques. In~\cite{Toshev2014-ou}, Toshev and Szegedy explore the application of \glspl{cnn} to estimate the body joints locations considering a cascade of Deep Neural Networks refining a coarse initial estimation. 
%Toshev and Szegedy~\cite{Toshev2014-ou} claim to be the first ones to explore the application of \glspl{cnn} to human pose estimation. 
%In their work, they regress body joints using a cascade of deep neural networks for refining a coarse initial estimation. 
%They tackle the human pose estimation task by estimating the body joints locations considering a cascade of Deep Neural Networks refining a coarse initial estimation. 
In~\cite{Tompson2014-iq}, Tompson \etal proposed a joint training of a hybrid architecture composed of a \gls{cnn} (as the part detector) with a part-based spatial model inspired on Markov Random Fields, 
%and a Markov Random Field inspired spatial model,
significantly outperforming previous methods. Since these works, most research in human pose estimation has shifted towards \gls{dl}-based solutions~\cite{Fan2015-zt, Bulat2016-in, Lifshitz2016-sg, Carreira2016-uk, Chu2017-io, Chen2017-pd, Yang2017-ao, Belagiannis2017-mf, Ke2018-xw, Newell2016-cy, Insafutdinov2016-ek, Wei2016-rb}. Newell \etal~\cite{Newell2016-cy} propose a novel \gls{cnn} architecture for this particular task forcing \textit{bottom-up} and \textit{top-down} processing with intermediate supervision. In~\cite{Wei2016-rb}, Wei \etal inherit the \textit{pose machines} architecture proposed by Ramakrishna \etal~\cite{Ramakrishna2014-ul}, but introducing \glspl{cnn} as feature detectors. Their sequential architecture, based on multiple stages which take as input belief maps from the previous stages, enables learning long-range dependencies among parts. A more general approach for spatial localization tasks is proposed by Gkioxari \etal~\cite{Gkioxari2016-ix}. Because of their intuitiveness and performance, we have chosen ~\cite{Newell2016-cy}, ~\cite{Wei2016-rb} and ~\cite{Gkioxari2016-ix} methods as 2D human pose estimators for our work. We will go deeper in these methods in Section~\ref{ch:proposed_method}. One of the most successful works published in the last years is the one proposed by Chen \etal~\cite{Chen2017-pd}. In order to deal with joint occlusions and overlapping of human body parts, they propose the usage of structure-aware \glspl{cnn} and Generative Adversarial Networks to train a pose generator only yielding plausible poses, implicitly learning priors about the human body structure. This approach is out of the scope of this paper because, to the best of our knowledge, there is no open source code available.

% 2D estimation with peculiar stuff like multiperson and video
The aforementioned works are focused on 2D pose estimation from individuals on single images. However, several authors have also tried to apply \gls{dl}-based techniques by taking advantage of the temporal information provided by sequences of images~\cite{Jain2015-zb, Pfister2015-ae, Song2017-fe, Girdhar2018-lx}. Such is the case of Pfister \etal~\cite{Pfister2015-ae}, who introduce in their pipeline dense optical flow estimations to warp estimated per-joint heatmaps in consecutive frames. In that way, the trained \gls{cnn} is forced to learn the temporal relationships between sequences of poses. Another approach to human pose estimation in 2D video is proposed by Girdhar \etal~\cite{Girdhar2018-lx}. In their work, they propose a 3D extension of the Mask Region-based \gls{cnn}  architecture to couple spatio-temporal information. \gls{dl}-based methods have also been employed in multi-person scenarios~\cite{Cao2017-fq, Iqbal2017-nu, Papandreou2017-nk, Insafutdinov2017-zx} and dense pose estimations, which map image pixels of the human body to its corresponding 3D surface~\cite{Alp_Guler2018-rg}.
% classic 3d methods, deep learning 3d methods. % however more used approach -> 2d to 3d regression (two stages). 

Regarding the 3D estimation methods, there are different approaches depending on the source of information. Estimating 3D locations from their 2D projections is a highly ill-posed problem, as very different 3D poses can generate very similar 2D projections. However, the \textit{a priori} knowledge about the human body and plausible poses, have allowed researchers to tackle this problem by means of hybrid approaches composed of two-stages: 2D estimation and 3D reconstruction from 2D projections. For instance, Andriluka \etal~\cite{Andriluka2010-oc} propose a complete framework for multi-person pose detection in videos using tracking-by-detection and 3D exemplars. Regarding the 3D reconstruction from 2D projections, Ramakrishna \etal~\cite{Ramakrishna2012-ti} propose an optimization proxy which jointly estimates 3D coordinates from 2D locations of anatomical landmarks and camera parameters while enforcing anthropometric regularity. Most recent methods introduce \glspl{cnn} for 3D estimation. Chen and Ramanan~\cite{Chen2017-ug} make use of the \glspl{cpm} proposed by Wei \etal~\cite{Wei2016-rb} for 2D estimation and then match the resulting pose with a library of 3D exemplars. In~\cite{Bogo2016-kk}, Bogo \etal estimate 2D poses with the DeepCut model proposed by Pischulin \etal~\cite{Pishchulin2013-zi} and then fit a statistical body shape model to the resulting 2D joints. However, \gls{dl}-based methods have not only been used for the 2D pose estimations, but they have also proved to be a very straightforward and effective solution for inferring 3D from 2D poses. Thus, Zhou \etal~\cite{Zhang2015-js} propose the inclusion of a \textit{depth regression module} taking the 2D heatmaps generated by a \gls{cnn} as input, providing a 3D pose estimation as the output. %Even a more direct \textcolor{red}{IMJ: Comentar con David, no tengo claro a qué nos referimos con more direct} approach is proposed by Martinez \etal~\cite{Martinez2017-su}. In their work, they outperform most of the state-of-the-art methods by simply using a multilayer neural network \textcolor{red}{IMJ: Comentar con David, porque no lo entiendo bien - \gls{dl} son tb redes neuronales multicapa. No entiendo la diferencia => REVISANDO EL DOCUMENTO, HE VISTO QUE THEY estimate body joint locations in 3-dimensional space given a 2-dimensional input Y PARA ELLO USAN UNA SENCILLA ARQUITECTURA simple, deep, multilayer neural network Y PRE-PROCESAN el 3d ground-truth according to the inverse transform of the camera, to make the 2d to 3d problem similar across different cameras ---- TRABAJAN CON EL  working with the camera frame by rotating and translating the 3d ground-truth according to the inverse transform of the camera, to make the 2d to 3d problem similar across different cameras}. 
A simple but effective approach is proposed by Martinez \etal~\cite{Martinez2017-su} by training a deep neural network to estimate 3D body joint locations from the corresponding 2D positions. For an adequate performance of the trained model, they consider the inverse transform of the camera to preprocess the 3D ground-truth before training, thus making the 2D to 3D problem similar across different cameras. Tome \etal~\cite{Tome2017-ja} propose a more sophisticated solution which not only predicts 3D poses but also uses them to improve their previous 2D estimation, blurring the separation between the two previously mentioned stages. Several authors~\cite{Nibali2019-yl, Luvizon2018-te, Pavlakos2017-qk, Nie2017-ud, Mehta2017-zi} have chosen direct inference instead of tackling the problem in these stages. Such is the case of the work proposed by Mehta \etal~\cite{Mehta2017-zi}. In their work, not only they infer 3D poses but also add temporal filtering and fit a kinematic skeleton model in order to take advantage of temporal correlation between frames.
 
% rgbd scenarios
The inclusion of depth measurements allows for higher accuracy and better understanding of the scene being analyzed. In~\cite{Youding_Zhu2008-pr}, Youding \etal use video stream from a time-of-flight sensor for detecting and tracking the position of anamotical landmarks using a probabilistic inferencing algorithm. Schwarz \etal~\cite{Schwarz2011-qi} try to solve the same task using geodesic distances and optical flow. A different approach is presented in~\cite{Ye2011-ui}, where Ye \etal estimate body pose by matching and refining pre-captured exemplars. Recently, \gls{dl}-based solutions have been proposed to address pose estimation from depth maps. Marín-Jimenez \etal~\cite{Marin-Jimenez2018-so} train a \gls{cnn} estimating 3D body poses as a linear combination of prototype poses. Moon \etal~\cite{Moon2018-xp} introduce the novelty of designing their model as a 3D \gls{cnn}, which estimates the likelihood per voxel for each joint in the pose. They test their model performance not only for addressing human pose estimation, but also hand pose. In~\cite{Zimmermann2018-sn}, Zimmermann \etal use a 2D keypoint detector to estimate the 2D pose, which is next used together with the depth map as input to train a \gls{cnn}  yielding predictions of real world 3D coordinates. These 3D predictions are used for robotic tasks learning.