\chapter{Introduction}\label{ch:introduction}

\textcolor{blue}{Azul: lista de cosas que faltan por contar;} \textcolor{red}{Rojo: a revisar y/o falta;}

% general introduction
In recent years, the increase in the computational capacity to collect and store data is producing a revolution in all areas of society (e.g. health, sports, education, finance, marketing, security or transport). Robotics is naturally involved in this revolution due to its enormous range of applications, from space to medicine, always with the aim of improving and making our lives more comfortable. %\textcolor{red}{En función de la aplicación final, quizá habría que modificar un poco esta parte para hacer más énfasis en esa "aplicación"}

% introduction to human pose estimation and its applications
As part of this revolution, \gls{ml} is also undergoing an unprecedented development, enabling many tasks to be performed in real-time, such as fraud detection, speech and face recognition or autonomous driving, just to mention a few ones~\cite{liu2017survey}. In this sense, even though all areas in robotics are influenced by developments in \gls{ml}, computer vision is perhaps the field which has experienced the most vertiginous growth. Furthermore, the growing interest in assistive robotics has enabled advances in some particular subfields of computer vision, such as human pose estimation, human detection and gesture recognition~\cite{leo2018deep}. In particular, human pose estimation is a very handy capability for assistive robots, such as personal or home robots, as it can serve as an input for solving higher level tasks, for instance, fall detection. Broadly speaking, a precise identification of human pose provides a better understanding of the scene, which is a major requirement for any human-robot interface.

\textcolor{red}{Motion-Capture systems are a well known solution for human pose estimation~\cite{Vicon}}. They typically provide a very precise 3D estimation but require some markers in the person to be tracked. There are many technologies for human pose estimation developed for \textcolor{red}{Ambient Assisted Living~\cite{}}. They use cameras or other sensors around the scenario to build their estimations. Typically the cameras are close to the ceiling and cover the area to monitor, having a \textcolor{red}{high point of view~\cite{OpenPose}}. The larger the area to monitor, the greater the number of involved cameras. In order to avoid the high costs of managing several cameras, to avoid the need of any installation and to make the system more portable to many homes it is advisable to endow the home robot with the human pose estimation algorithm using only its sensors or cameras. Here the point of view of the cameras is not so high and there may be temporary occlusions, but the robot itself may move around the scenario for clearer views if needed.

The spectacular development of computer vision has been possible due to the push from \gls{dl} techniques, a field of ML enabling to create complex models trained with huge amounts of examples associated to the task to be solved. Thanks to the inclusion of \gls{dl} based techniques, specially \glspl{cnn}, the performance of human pose estimation methods has significantly increased in the last years. This factor, in conjunction with the need for more reliable ways of understanding real scenes in applications such as video surveillance, human activity monitoring and human-computer interaction~\cite{sarafianos20163d}, has favored an increasing interest in research within this field. The great variety of tasks that can be addressed through human pose estimation has lead to the development of many different approaches. Some solutions are designed considering 2D or 3D single images~\cite{dang2019deep}, while others take video streams into consideration~\cite{Gong2016-kd, ye2013survey}. Regarding the output provided by the design, there are also different possibilities ranging from 2D and 3D joints locations~\cite{perez2014survey} to dense estimations~\cite{Alp_Guler2018-rg}.

% current challenges
While the irruption of \gls{dl} has had an undeniable beneficial impact in the development of the field of human pose estimation, the needed amount of real-world data for designing models achieving a good performance is still an issue, as capture and annotation processes are costly and very time consuming. This is specially true for 3D images, where motion capture systems are usually needed for collecting reliable annotations~\cite{ionescu2013human3, sigal2010humaneva}. As a consequence, there is a strong gap in the number of publicly available large-scale datasets in favor of the two-dimensional ones. While 2D estimations might be enough for solving some particular tasks like action recognition~\cite{liu2018recognizing}, 3D estimations are needed in order to achieve a complete visual understanding of the scene~\cite{sarafianos20163d}. Fortunately, the emergence of robust RGBD sensors at affordable prices allows the integration of real 3D information into human pose estimation pipelines.

% our main contributions
In this work, we propose and implement an end-to-end pipeline for augmenting 2D human pose estimations into 3D estimations in real time. This perceptive algorithm is intended to be run on-board in many assistive or home robots: it works in real time in an off-the-shelf computer, it works with regular RGBD cameras, which are common in robotics, and when those cameras are placed at typical robot height, not close to the ceiling. We have validated it experimentally and performed a wide and detailed comparison with some of the most relevant human pose estimation algorithms, using Berkeley's Multimodal Human Action Database (BMHAD)\cite{ofli2013berkeley}, which is a publicly available and well-known international dataset.

\textcolor{blue}{Iterar contribuciones en función de dónde apuntemos??}

\textcolor{red}{
Our main contributions are summarized as follows:
\begin{itemize}[leftmargin=*,labelsep=5.8mm]
\item We evaluate the performance and accuracy of multiple state-of-the-art methods for 2D human pose estimation;
\item We propose and evaluate a straight-forward pipeline for augmenting 2D estimations into 3D estimations in real-time with the inclusion of an RGBD sensor;
\item We evaluate and compare our 3D human pose estimation method with a state-of-the-art \gls{dl} algorithm;
\item\sout{We build a web-based 3D visualization tool for human activity monitoring;}
\item We demonstrate our proposed pipeline performance with a practical use case for assistive robotics;
\end{itemize}
}

% paper structure
\textcolor{red}{Esta parte, queda pendiente. Hacerla cuando tengamos la estructura completa} The rest of this paper is structured as follows. In Section~\ref{relatedwork}, a review of related work and state-of-the-art methods is presented. In Section~\ref{proposedmethod}, each step in the proposed pipeline is described in detail. The experiments carried out to evaluate the performance of this pipeline are presented in Section~\ref{experiments}. Finally, results are discussed and summarized in Section~\ref{conclusions}.